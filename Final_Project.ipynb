{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf4e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cf7e873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70687</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70688</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70689</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70690</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70691</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70692 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0                  0.0     1.0       0.0        1.0  26.0     0.0     0.0   \n",
       "1                  0.0     1.0       1.0        1.0  26.0     1.0     1.0   \n",
       "2                  0.0     0.0       0.0        1.0  26.0     0.0     0.0   \n",
       "3                  0.0     1.0       1.0        1.0  28.0     1.0     0.0   \n",
       "4                  0.0     0.0       0.0        1.0  29.0     1.0     0.0   \n",
       "...                ...     ...       ...        ...   ...     ...     ...   \n",
       "70687              1.0     0.0       1.0        1.0  37.0     0.0     0.0   \n",
       "70688              1.0     0.0       1.0        1.0  29.0     1.0     0.0   \n",
       "70689              1.0     1.0       1.0        1.0  25.0     0.0     0.0   \n",
       "70690              1.0     1.0       1.0        1.0  18.0     0.0     0.0   \n",
       "70691              1.0     1.0       1.0        1.0  25.0     0.0     0.0   \n",
       "\n",
       "       HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                       0.0           1.0     0.0  ...            1.0   \n",
       "1                       0.0           0.0     1.0  ...            1.0   \n",
       "2                       0.0           1.0     1.0  ...            1.0   \n",
       "3                       0.0           1.0     1.0  ...            1.0   \n",
       "4                       0.0           1.0     1.0  ...            1.0   \n",
       "...                     ...           ...     ...  ...            ...   \n",
       "70687                   0.0           0.0     0.0  ...            1.0   \n",
       "70688                   1.0           0.0     1.0  ...            1.0   \n",
       "70689                   1.0           0.0     1.0  ...            1.0   \n",
       "70690                   0.0           0.0     0.0  ...            1.0   \n",
       "70691                   1.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "       NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  \\\n",
       "0              0.0      3.0       5.0      30.0       0.0  1.0   4.0   \n",
       "1              0.0      3.0       0.0       0.0       0.0  1.0  12.0   \n",
       "2              0.0      1.0       0.0      10.0       0.0  1.0  13.0   \n",
       "3              0.0      3.0       0.0       3.0       0.0  1.0  11.0   \n",
       "4              0.0      2.0       0.0       0.0       0.0  0.0   8.0   \n",
       "...            ...      ...       ...       ...       ...  ...   ...   \n",
       "70687          0.0      4.0       0.0       0.0       0.0  0.0   6.0   \n",
       "70688          0.0      2.0       0.0       0.0       1.0  1.0  10.0   \n",
       "70689          0.0      5.0      15.0       0.0       1.0  0.0  13.0   \n",
       "70690          0.0      4.0       0.0       0.0       1.0  0.0  11.0   \n",
       "70691          0.0      2.0       0.0       0.0       0.0  0.0   9.0   \n",
       "\n",
       "       Education  Income  \n",
       "0            6.0     8.0  \n",
       "1            6.0     8.0  \n",
       "2            6.0     8.0  \n",
       "3            6.0     8.0  \n",
       "4            5.0     8.0  \n",
       "...          ...     ...  \n",
       "70687        4.0     1.0  \n",
       "70688        3.0     6.0  \n",
       "70689        6.0     4.0  \n",
       "70690        2.0     4.0  \n",
       "70691        6.0     2.0  \n",
       "\n",
       "[70692 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the data\n",
    "df = pd.read_csv('diabetes_binary_5050split_health_indicators_BRFSS2015.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c0a6fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90187b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70692, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9af53111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70692 entries, 0 to 70691\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Diabetes_binary       70692 non-null  float64\n",
      " 1   HighBP                70692 non-null  float64\n",
      " 2   HighChol              70692 non-null  float64\n",
      " 3   CholCheck             70692 non-null  float64\n",
      " 4   BMI                   70692 non-null  float64\n",
      " 5   Smoker                70692 non-null  float64\n",
      " 6   Stroke                70692 non-null  float64\n",
      " 7   HeartDiseaseorAttack  70692 non-null  float64\n",
      " 8   PhysActivity          70692 non-null  float64\n",
      " 9   Fruits                70692 non-null  float64\n",
      " 10  Veggies               70692 non-null  float64\n",
      " 11  HvyAlcoholConsump     70692 non-null  float64\n",
      " 12  AnyHealthcare         70692 non-null  float64\n",
      " 13  NoDocbcCost           70692 non-null  float64\n",
      " 14  GenHlth               70692 non-null  float64\n",
      " 15  MentHlth              70692 non-null  float64\n",
      " 16  PhysHlth              70692 non-null  float64\n",
      " 17  DiffWalk              70692 non-null  float64\n",
      " 18  Sex                   70692 non-null  float64\n",
      " 19  Age                   70692 non-null  float64\n",
      " 20  Education             70692 non-null  float64\n",
      " 21  Income                70692 non-null  float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 11.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78014199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes_binary          2\n",
       "HighBP                   2\n",
       "HighChol                 2\n",
       "CholCheck                2\n",
       "BMI                     80\n",
       "Smoker                   2\n",
       "Stroke                   2\n",
       "HeartDiseaseorAttack     2\n",
       "PhysActivity             2\n",
       "Fruits                   2\n",
       "Veggies                  2\n",
       "HvyAlcoholConsump        2\n",
       "AnyHealthcare            2\n",
       "NoDocbcCost              2\n",
       "GenHlth                  5\n",
       "MentHlth                31\n",
       "PhysHlth                31\n",
       "DiffWalk                 2\n",
       "Sex                      2\n",
       "Age                     13\n",
       "Education                6\n",
       "Income                   8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "408d1623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.0    6327\n",
       "26.0    4975\n",
       "28.0    4583\n",
       "24.0    4392\n",
       "30.0    4344\n",
       "Name: BMI, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmi = df['BMI'].value_counts()\n",
    "bmi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25baf1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    23427\n",
       "2.0    19872\n",
       "4.0    13303\n",
       "1.0     8282\n",
       "5.0     5808\n",
       "Name: GenHlth, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genhlth = df['GenHlth'].value_counts()\n",
    "genhlth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d292376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     48091\n",
       "30.0     4320\n",
       "2.0      3267\n",
       "5.0      2519\n",
       "1.0      2051\n",
       "Name: MentHlth, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menthlth = df['MentHlth'].value_counts()\n",
    "menthlth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88060fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     39915\n",
       "30.0     7953\n",
       "2.0      4102\n",
       "1.0      2853\n",
       "3.0      2438\n",
       "Name: PhysHlth, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physhlth = df['PhysHlth'].value_counts()\n",
    "physhlth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "706c9a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0    10856\n",
       "9.0     10112\n",
       "8.0      8603\n",
       "11.0     8044\n",
       "7.0      6872\n",
       "13.0     5426\n",
       "12.0     5394\n",
       "6.0      4648\n",
       "5.0      3520\n",
       "4.0      2793\n",
       "3.0      2049\n",
       "2.0      1396\n",
       "1.0       979\n",
       "Name: Age, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age = df['Age'].value_counts()\n",
    "age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecdab459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0    26020\n",
       "5.0    20030\n",
       "4.0    19473\n",
       "3.0     3447\n",
       "2.0     1647\n",
       "1.0       75\n",
       "Name: Education, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education = df['Education'].value_counts()\n",
    "education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "384c5a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0    20646\n",
       "7.0    11425\n",
       "6.0    10287\n",
       "5.0     8010\n",
       "4.0     6658\n",
       "3.0     5557\n",
       "2.0     4498\n",
       "1.0     3611\n",
       "Name: Income, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income = df['Income'].value_counts()\n",
    "income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29200c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Diabetes_binary', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker',\n",
       "       'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
       "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
       "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
       "       'Income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80201c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting preprocessed data into feature and target arrays\n",
    "x = df.drop('Diabetes_binary', axis = 1).values\n",
    "y = df['Diabetes_binary'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27392691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1., ...,  4.,  6.,  8.],\n",
       "       [ 1.,  1.,  1., ..., 12.,  6.,  8.],\n",
       "       [ 0.,  0.,  1., ..., 13.,  6.,  8.],\n",
       "       ...,\n",
       "       [ 1.,  1.,  1., ..., 13.,  6.,  4.],\n",
       "       [ 1.,  1.,  1., ..., 11.,  2.,  4.],\n",
       "       [ 1.,  1.,  1., ...,  9.,  6.,  2.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8acb5066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7db68b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting preprocessed data into training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state = 66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7a8ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58e1a582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53019, 21)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "288b07d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Model\n",
    "\n",
    "# Defining number of input features\n",
    "input_features = X_train_scaled.shape[1]\n",
    "\n",
    "# Defining number of nodes for each layer\n",
    "hidden_node_1 = 20\n",
    "hidden_node_2 = 10\n",
    "\n",
    "# Instantiating the sequential model\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units = hidden_node_1, activation = 'relu', input_dim = input_features))\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units = hidden_node_2, activation = 'relu'))\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d790c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 20)                440       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 661 (2.58 KB)\n",
      "Trainable params: 661 (2.58 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7d77b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "nn.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35f7f36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1657/1657 [==============================] - 3s 1ms/step - loss: 0.5211 - accuracy: 0.7428\n",
      "Epoch 2/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.5056 - accuracy: 0.7524\n",
      "Epoch 3/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.5026 - accuracy: 0.7535\n",
      "Epoch 4/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.5010 - accuracy: 0.7540\n",
      "Epoch 5/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.5000 - accuracy: 0.7559\n",
      "Epoch 6/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.4995 - accuracy: 0.7555\n",
      "Epoch 7/50\n",
      "1657/1657 [==============================] - 4s 2ms/step - loss: 0.4988 - accuracy: 0.7571\n",
      "Epoch 8/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4982 - accuracy: 0.7573\n",
      "Epoch 9/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.4981 - accuracy: 0.7570\n",
      "Epoch 10/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4974 - accuracy: 0.7578\n",
      "Epoch 11/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.4975 - accuracy: 0.7580\n",
      "Epoch 12/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.4971 - accuracy: 0.7581\n",
      "Epoch 13/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.4969 - accuracy: 0.7574\n",
      "Epoch 14/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.4965 - accuracy: 0.7580\n",
      "Epoch 15/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4965 - accuracy: 0.7591\n",
      "Epoch 16/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.4963 - accuracy: 0.7580\n",
      "Epoch 17/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.4959 - accuracy: 0.7582\n",
      "Epoch 18/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.4958 - accuracy: 0.7571\n",
      "Epoch 19/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.4955 - accuracy: 0.7580\n",
      "Epoch 20/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.4952 - accuracy: 0.7586\n",
      "Epoch 21/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.4951 - accuracy: 0.7588\n",
      "Epoch 22/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.4948 - accuracy: 0.7578\n",
      "Epoch 23/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.4947 - accuracy: 0.7587\n",
      "Epoch 24/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.4948 - accuracy: 0.7586\n",
      "Epoch 25/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.4945 - accuracy: 0.7589\n",
      "Epoch 26/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.4942 - accuracy: 0.7581\n",
      "Epoch 27/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.4942 - accuracy: 0.7594\n",
      "Epoch 28/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.4941 - accuracy: 0.7585\n",
      "Epoch 29/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.4937 - accuracy: 0.7600\n",
      "Epoch 30/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4937 - accuracy: 0.7595\n",
      "Epoch 31/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4937 - accuracy: 0.7587\n",
      "Epoch 32/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4935 - accuracy: 0.7598\n",
      "Epoch 33/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4932 - accuracy: 0.7602\n",
      "Epoch 34/50\n",
      "1657/1657 [==============================] - 4s 2ms/step - loss: 0.4932 - accuracy: 0.7591\n",
      "Epoch 35/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4931 - accuracy: 0.7589\n",
      "Epoch 36/50\n",
      "1657/1657 [==============================] - 4s 3ms/step - loss: 0.4932 - accuracy: 0.7595\n",
      "Epoch 37/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4930 - accuracy: 0.7594\n",
      "Epoch 38/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4929 - accuracy: 0.7603\n",
      "Epoch 39/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4928 - accuracy: 0.7604\n",
      "Epoch 40/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4927 - accuracy: 0.7604\n",
      "Epoch 41/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4925 - accuracy: 0.7597\n",
      "Epoch 42/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4927 - accuracy: 0.7605\n",
      "Epoch 43/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4926 - accuracy: 0.7597\n",
      "Epoch 44/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4925 - accuracy: 0.7602\n",
      "Epoch 45/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4926 - accuracy: 0.7592\n",
      "Epoch 46/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4921 - accuracy: 0.7606\n",
      "Epoch 47/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4923 - accuracy: 0.7606\n",
      "Epoch 48/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4921 - accuracy: 0.7610\n",
      "Epoch 49/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4925 - accuracy: 0.7603\n",
      "Epoch 50/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4920 - accuracy: 0.7602\n"
     ]
    }
   ],
   "source": [
    "model = nn.fit(X_train_scaled, y_train, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e44a7a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553/553 - 1s - loss: 0.5079 - accuracy: 0.7506 - 602ms/epoch - 1ms/step\n",
      "loss: 0.5078632235527039, accuracy: 0.7506365776062012\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose = 2)\n",
    "print(f'loss: {model_loss}, accuracy: {model_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41647f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Second Model\n",
    "\n",
    "# Defining number of input features\n",
    "input_features = X_train_scaled.shape[1]\n",
    "\n",
    "# Defining number of nodes for each layer\n",
    "hidden_node_1 = 20\n",
    "hidden_node_2 = 10\n",
    "\n",
    "# Instantiating the sequential model\n",
    "nn2 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units = hidden_node_1, activation = 'tanh', input_dim = input_features))\n",
    "# Second hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units = hidden_node_2, activation = 'tanh'))\n",
    "# Output layer\n",
    "nn2.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95f653fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 20)                440       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 661 (2.58 KB)\n",
      "Trainable params: 661 (2.58 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking the structure of the model\n",
    "nn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78defb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "nn2.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcbd11a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1657/1657 [==============================] - 3s 1ms/step - loss: 0.5217 - accuracy: 0.7413\n",
      "Epoch 2/50\n",
      "1657/1657 [==============================] - 4s 2ms/step - loss: 0.5094 - accuracy: 0.7501\n",
      "Epoch 3/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.5064 - accuracy: 0.7520\n",
      "Epoch 4/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.5045 - accuracy: 0.7514\n",
      "Epoch 5/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.5031 - accuracy: 0.7537\n",
      "Epoch 6/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.5022 - accuracy: 0.7536\n",
      "Epoch 7/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.5010 - accuracy: 0.7541\n",
      "Epoch 8/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.5006 - accuracy: 0.7552\n",
      "Epoch 9/50\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.5000 - accuracy: 0.7540\n",
      "Epoch 10/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4991 - accuracy: 0.7566\n",
      "Epoch 11/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4989 - accuracy: 0.7567\n",
      "Epoch 12/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4986 - accuracy: 0.7562\n",
      "Epoch 13/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4980 - accuracy: 0.7567\n",
      "Epoch 14/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4974 - accuracy: 0.7559\n",
      "Epoch 15/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4972 - accuracy: 0.7560\n",
      "Epoch 16/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4971 - accuracy: 0.7570\n",
      "Epoch 17/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4965 - accuracy: 0.7573\n",
      "Epoch 18/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4965 - accuracy: 0.7569\n",
      "Epoch 19/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4961 - accuracy: 0.7578\n",
      "Epoch 20/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4959 - accuracy: 0.7572\n",
      "Epoch 21/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4956 - accuracy: 0.7573\n",
      "Epoch 22/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4956 - accuracy: 0.7578\n",
      "Epoch 23/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4952 - accuracy: 0.7584\n",
      "Epoch 24/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4951 - accuracy: 0.7589\n",
      "Epoch 25/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4952 - accuracy: 0.7575\n",
      "Epoch 26/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4947 - accuracy: 0.7588\n",
      "Epoch 27/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4945 - accuracy: 0.7586\n",
      "Epoch 28/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4944 - accuracy: 0.7581\n",
      "Epoch 29/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4942 - accuracy: 0.7588\n",
      "Epoch 30/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4942 - accuracy: 0.7604\n",
      "Epoch 31/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4941 - accuracy: 0.7590\n",
      "Epoch 32/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4940 - accuracy: 0.7591\n",
      "Epoch 33/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4938 - accuracy: 0.7597\n",
      "Epoch 34/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4936 - accuracy: 0.7600\n",
      "Epoch 35/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4935 - accuracy: 0.7600\n",
      "Epoch 36/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4932 - accuracy: 0.7593\n",
      "Epoch 37/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4930 - accuracy: 0.7593\n",
      "Epoch 38/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4930 - accuracy: 0.7595\n",
      "Epoch 39/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4927 - accuracy: 0.7601\n",
      "Epoch 40/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4926 - accuracy: 0.7603\n",
      "Epoch 41/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4924 - accuracy: 0.7598\n",
      "Epoch 42/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4924 - accuracy: 0.7603\n",
      "Epoch 43/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4922 - accuracy: 0.7606\n",
      "Epoch 44/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4921 - accuracy: 0.7603\n",
      "Epoch 45/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4921 - accuracy: 0.7604\n",
      "Epoch 46/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4920 - accuracy: 0.7600\n",
      "Epoch 47/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4918 - accuracy: 0.7604\n",
      "Epoch 48/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4917 - accuracy: 0.7604\n",
      "Epoch 49/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4917 - accuracy: 0.7598\n",
      "Epoch 50/50\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4915 - accuracy: 0.7615\n"
     ]
    }
   ],
   "source": [
    "model_2 = nn2.fit(X_train_scaled, y_train, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29aedddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553/553 - 1s - loss: 0.5102 - accuracy: 0.7497 - 529ms/epoch - 956us/step\n",
      "loss: 0.510181188583374, accuracy: 0.7497312426567078\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model using the test data\n",
    "model_loss, model_accuracy = nn2.evaluate(X_test_scaled, y_test, verbose = 2)\n",
    "print(f'loss: {model_loss}, accuracy: {model_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "186473f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Third Model\n",
    "\n",
    "# Defining number of input features\n",
    "input_features = X_train_scaled.shape[1]\n",
    "\n",
    "# Defining number of nodes for each layer\n",
    "hidden_node_1 = 40\n",
    "hidden_node_2 = 20\n",
    "hidden_node_3 = 10\n",
    "\n",
    "# Instantiating the sequential model\n",
    "nn3 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units = hidden_node_1, activation = 'tanh', input_dim = input_features))\n",
    "# Second hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units = hidden_node_2, activation = 'tanh'))\n",
    "# Third hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units = hidden_node_3, activation = 'tanh'))\n",
    "# Output layer\n",
    "nn3.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ab46011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 40)                880       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 20)                820       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1921 (7.50 KB)\n",
      "Trainable params: 1921 (7.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking the structure of the model\n",
    "nn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "074a84e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "nn3.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "812b11c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1657/1657 [==============================] - 4s 2ms/step - loss: 0.5181 - accuracy: 0.7451\n",
      "Epoch 2/100\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.5081 - accuracy: 0.7499\n",
      "Epoch 3/100\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.5047 - accuracy: 0.7529\n",
      "Epoch 4/100\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.5028 - accuracy: 0.7548\n",
      "Epoch 5/100\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.5014 - accuracy: 0.7539\n",
      "Epoch 6/100\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.5003 - accuracy: 0.7549\n",
      "Epoch 7/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4992 - accuracy: 0.7552\n",
      "Epoch 8/100\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.4983 - accuracy: 0.7571\n",
      "Epoch 9/100\n",
      "1657/1657 [==============================] - 4s 2ms/step - loss: 0.4974 - accuracy: 0.7567\n",
      "Epoch 10/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4967 - accuracy: 0.7573\n",
      "Epoch 11/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4957 - accuracy: 0.7581\n",
      "Epoch 12/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4951 - accuracy: 0.7580\n",
      "Epoch 13/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4943 - accuracy: 0.7590\n",
      "Epoch 14/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4934 - accuracy: 0.7593\n",
      "Epoch 15/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4925 - accuracy: 0.7603\n",
      "Epoch 16/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4925 - accuracy: 0.7600\n",
      "Epoch 17/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4915 - accuracy: 0.7599\n",
      "Epoch 18/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4909 - accuracy: 0.7623\n",
      "Epoch 19/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4900 - accuracy: 0.7623\n",
      "Epoch 20/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4896 - accuracy: 0.7612\n",
      "Epoch 21/100\n",
      "1657/1657 [==============================] - 4s 2ms/step - loss: 0.4889 - accuracy: 0.7613\n",
      "Epoch 22/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4883 - accuracy: 0.7618\n",
      "Epoch 23/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4878 - accuracy: 0.7614\n",
      "Epoch 24/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4871 - accuracy: 0.7629\n",
      "Epoch 25/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4864 - accuracy: 0.7633\n",
      "Epoch 26/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4857 - accuracy: 0.7638\n",
      "Epoch 27/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4850 - accuracy: 0.7657\n",
      "Epoch 28/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4847 - accuracy: 0.7651\n",
      "Epoch 29/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4840 - accuracy: 0.7644\n",
      "Epoch 30/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4832 - accuracy: 0.7659\n",
      "Epoch 31/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4828 - accuracy: 0.7660\n",
      "Epoch 32/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4823 - accuracy: 0.7657\n",
      "Epoch 33/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4814 - accuracy: 0.7665\n",
      "Epoch 34/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4809 - accuracy: 0.7674\n",
      "Epoch 35/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4807 - accuracy: 0.7660\n",
      "Epoch 36/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4801 - accuracy: 0.7672\n",
      "Epoch 37/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4793 - accuracy: 0.7663\n",
      "Epoch 38/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4787 - accuracy: 0.7683\n",
      "Epoch 39/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4788 - accuracy: 0.7677\n",
      "Epoch 40/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4779 - accuracy: 0.7684\n",
      "Epoch 41/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4775 - accuracy: 0.7695\n",
      "Epoch 42/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4771 - accuracy: 0.7693\n",
      "Epoch 43/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4767 - accuracy: 0.7698\n",
      "Epoch 44/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4762 - accuracy: 0.7690\n",
      "Epoch 45/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4757 - accuracy: 0.7704\n",
      "Epoch 46/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4750 - accuracy: 0.7705\n",
      "Epoch 47/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4746 - accuracy: 0.7704\n",
      "Epoch 48/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4744 - accuracy: 0.7705\n",
      "Epoch 49/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4738 - accuracy: 0.7712\n",
      "Epoch 50/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4732 - accuracy: 0.7720\n",
      "Epoch 51/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4729 - accuracy: 0.7721\n",
      "Epoch 52/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4723 - accuracy: 0.7719\n",
      "Epoch 53/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4722 - accuracy: 0.7730\n",
      "Epoch 54/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4718 - accuracy: 0.7726\n",
      "Epoch 55/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4714 - accuracy: 0.7734\n",
      "Epoch 56/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4707 - accuracy: 0.7738\n",
      "Epoch 57/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4704 - accuracy: 0.7733\n",
      "Epoch 58/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4700 - accuracy: 0.7740\n",
      "Epoch 59/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4698 - accuracy: 0.7739\n",
      "Epoch 60/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4693 - accuracy: 0.7748\n",
      "Epoch 61/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4687 - accuracy: 0.7753\n",
      "Epoch 62/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4684 - accuracy: 0.7746\n",
      "Epoch 63/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4680 - accuracy: 0.7750\n",
      "Epoch 64/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4675 - accuracy: 0.7755\n",
      "Epoch 65/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4671 - accuracy: 0.7755\n",
      "Epoch 66/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4671 - accuracy: 0.7760\n",
      "Epoch 67/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4662 - accuracy: 0.7756\n",
      "Epoch 68/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4662 - accuracy: 0.7753\n",
      "Epoch 69/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4658 - accuracy: 0.7767\n",
      "Epoch 70/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4654 - accuracy: 0.7764\n",
      "Epoch 71/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4651 - accuracy: 0.7763\n",
      "Epoch 72/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4650 - accuracy: 0.7773\n",
      "Epoch 73/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4643 - accuracy: 0.7767\n",
      "Epoch 74/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4640 - accuracy: 0.7776\n",
      "Epoch 75/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4634 - accuracy: 0.7776\n",
      "Epoch 76/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4636 - accuracy: 0.7773\n",
      "Epoch 77/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4629 - accuracy: 0.7787\n",
      "Epoch 78/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4629 - accuracy: 0.7793\n",
      "Epoch 79/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4624 - accuracy: 0.7784\n",
      "Epoch 80/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4623 - accuracy: 0.7781\n",
      "Epoch 81/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4618 - accuracy: 0.7790\n",
      "Epoch 82/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4616 - accuracy: 0.7783\n",
      "Epoch 83/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4615 - accuracy: 0.7787\n",
      "Epoch 84/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4612 - accuracy: 0.7800\n",
      "Epoch 85/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4608 - accuracy: 0.7794\n",
      "Epoch 86/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4606 - accuracy: 0.7790\n",
      "Epoch 87/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4602 - accuracy: 0.7787\n",
      "Epoch 88/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4605 - accuracy: 0.7798\n",
      "Epoch 89/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4600 - accuracy: 0.7797\n",
      "Epoch 90/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4597 - accuracy: 0.7788\n",
      "Epoch 91/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4595 - accuracy: 0.7789\n",
      "Epoch 92/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4590 - accuracy: 0.7800\n",
      "Epoch 93/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4593 - accuracy: 0.7789\n",
      "Epoch 94/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4588 - accuracy: 0.7789\n",
      "Epoch 95/100\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.4587 - accuracy: 0.7796\n",
      "Epoch 96/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4586 - accuracy: 0.7805\n",
      "Epoch 97/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4585 - accuracy: 0.7802\n",
      "Epoch 98/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4581 - accuracy: 0.7793\n",
      "Epoch 99/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4578 - accuracy: 0.7792\n",
      "Epoch 100/100\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4579 - accuracy: 0.7796\n"
     ]
    }
   ],
   "source": [
    "model_3 = nn3.fit(X_train_scaled, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c023a8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553/553 - 1s - loss: 0.5459 - accuracy: 0.7294 - 738ms/epoch - 1ms/step\n",
      "loss: 0.5458769202232361, accuracy: 0.7294177412986755\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model using the test data\n",
    "model_loss, model_accuracy = nn3.evaluate(X_test_scaled, y_test, verbose = 2)\n",
    "print(f'loss: {model_loss}, accuracy: {model_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77c9168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Fourth Model\n",
    "\n",
    "# Defining number of input features\n",
    "input_features = X_train_scaled.shape[1]\n",
    "\n",
    "# Defining number of nodes for each layer\n",
    "hidden_node_1 = 80\n",
    "hidden_node_2 = 40\n",
    "hidden_node_3 = 20\n",
    "hidden_node_4 = 10\n",
    "hidden_node_5 = 10\n",
    "hidden_node_6 = 10\n",
    "\n",
    "# Instantiating the sequential model\n",
    "nn4 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units = hidden_node_1, activation = 'tanh', input_dim = input_features))\n",
    "# Second hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units = hidden_node_2, activation = 'tanh'))\n",
    "# Third hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units = hidden_node_3, activation = 'relu'))\n",
    "# Fourth hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units = hidden_node_4, activation = 'tanh'))\n",
    "# Fifth hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units = hidden_node_5, activation = 'relu'))\n",
    "# Sixth hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units = hidden_node_6, activation = 'tanh'))\n",
    "# Output layer\n",
    "nn4.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f85583f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 80)                1760      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 40)                3240      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 20)                820       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6261 (24.46 KB)\n",
      "Trainable params: 6261 (24.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking the structure of the model\n",
    "nn4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1a97858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "nn4.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e63baa55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1657/1657 [==============================] - 5s 2ms/step - loss: 0.5177 - accuracy: 0.7453\n",
      "Epoch 2/200\n",
      "1657/1657 [==============================] - 4s 2ms/step - loss: 0.5076 - accuracy: 0.7498\n",
      "Epoch 3/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.5058 - accuracy: 0.7525\n",
      "Epoch 4/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.5034 - accuracy: 0.7540\n",
      "Epoch 5/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.5012 - accuracy: 0.7542\n",
      "Epoch 6/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.5005 - accuracy: 0.7556\n",
      "Epoch 7/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4988 - accuracy: 0.7562\n",
      "Epoch 8/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4966 - accuracy: 0.7575\n",
      "Epoch 9/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4950 - accuracy: 0.7590\n",
      "Epoch 10/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4938 - accuracy: 0.7597\n",
      "Epoch 11/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4916 - accuracy: 0.7606\n",
      "Epoch 12/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4913 - accuracy: 0.7606\n",
      "Epoch 13/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4896 - accuracy: 0.7617\n",
      "Epoch 14/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4875 - accuracy: 0.7627\n",
      "Epoch 15/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4867 - accuracy: 0.7630\n",
      "Epoch 16/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4845 - accuracy: 0.7654\n",
      "Epoch 17/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4830 - accuracy: 0.7670\n",
      "Epoch 18/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4813 - accuracy: 0.7680\n",
      "Epoch 19/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4790 - accuracy: 0.7679\n",
      "Epoch 20/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4781 - accuracy: 0.7689\n",
      "Epoch 21/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4758 - accuracy: 0.7708\n",
      "Epoch 22/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4739 - accuracy: 0.7723\n",
      "Epoch 23/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4725 - accuracy: 0.7737\n",
      "Epoch 24/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4710 - accuracy: 0.7746\n",
      "Epoch 25/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4694 - accuracy: 0.7757\n",
      "Epoch 26/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4675 - accuracy: 0.7759\n",
      "Epoch 27/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4656 - accuracy: 0.7781\n",
      "Epoch 28/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4634 - accuracy: 0.7791\n",
      "Epoch 29/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4622 - accuracy: 0.7799\n",
      "Epoch 30/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4606 - accuracy: 0.7810\n",
      "Epoch 31/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4582 - accuracy: 0.7824\n",
      "Epoch 32/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4566 - accuracy: 0.7827\n",
      "Epoch 33/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4557 - accuracy: 0.7845\n",
      "Epoch 34/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4535 - accuracy: 0.7858\n",
      "Epoch 35/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4528 - accuracy: 0.7870\n",
      "Epoch 36/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4508 - accuracy: 0.7877\n",
      "Epoch 37/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4495 - accuracy: 0.7868\n",
      "Epoch 38/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4474 - accuracy: 0.7891\n",
      "Epoch 39/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4467 - accuracy: 0.7897\n",
      "Epoch 40/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4446 - accuracy: 0.7901\n",
      "Epoch 41/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4427 - accuracy: 0.7929\n",
      "Epoch 42/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4417 - accuracy: 0.7914\n",
      "Epoch 43/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4404 - accuracy: 0.7937\n",
      "Epoch 44/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4386 - accuracy: 0.7934\n",
      "Epoch 45/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4380 - accuracy: 0.7944\n",
      "Epoch 46/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4359 - accuracy: 0.7964\n",
      "Epoch 47/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4354 - accuracy: 0.7959\n",
      "Epoch 48/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4340 - accuracy: 0.7981\n",
      "Epoch 49/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4324 - accuracy: 0.7983\n",
      "Epoch 50/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4320 - accuracy: 0.7981\n",
      "Epoch 51/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4300 - accuracy: 0.7990\n",
      "Epoch 52/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4299 - accuracy: 0.7984\n",
      "Epoch 53/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4268 - accuracy: 0.8015\n",
      "Epoch 54/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4270 - accuracy: 0.8007\n",
      "Epoch 55/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4264 - accuracy: 0.8018\n",
      "Epoch 56/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4244 - accuracy: 0.8026\n",
      "Epoch 57/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4243 - accuracy: 0.8014\n",
      "Epoch 58/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4228 - accuracy: 0.8034\n",
      "Epoch 59/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4211 - accuracy: 0.8036\n",
      "Epoch 60/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4206 - accuracy: 0.8046\n",
      "Epoch 61/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4198 - accuracy: 0.8050\n",
      "Epoch 62/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4197 - accuracy: 0.8064\n",
      "Epoch 63/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4182 - accuracy: 0.8061\n",
      "Epoch 64/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4160 - accuracy: 0.8074\n",
      "Epoch 65/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4158 - accuracy: 0.8067\n",
      "Epoch 66/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4146 - accuracy: 0.8082\n",
      "Epoch 67/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4146 - accuracy: 0.8078\n",
      "Epoch 68/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4143 - accuracy: 0.8083\n",
      "Epoch 69/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4122 - accuracy: 0.8099\n",
      "Epoch 70/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4121 - accuracy: 0.8092\n",
      "Epoch 71/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4112 - accuracy: 0.8101\n",
      "Epoch 72/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4115 - accuracy: 0.8109\n",
      "Epoch 73/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4101 - accuracy: 0.8103\n",
      "Epoch 74/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4092 - accuracy: 0.8113\n",
      "Epoch 75/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4082 - accuracy: 0.8137\n",
      "Epoch 76/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4084 - accuracy: 0.8107\n",
      "Epoch 77/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4076 - accuracy: 0.8130\n",
      "Epoch 78/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4076 - accuracy: 0.8125\n",
      "Epoch 79/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4065 - accuracy: 0.8117\n",
      "Epoch 80/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4069 - accuracy: 0.8120\n",
      "Epoch 81/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4049 - accuracy: 0.8136\n",
      "Epoch 82/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4040 - accuracy: 0.8141\n",
      "Epoch 83/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4038 - accuracy: 0.8143\n",
      "Epoch 84/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4033 - accuracy: 0.8142\n",
      "Epoch 85/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4030 - accuracy: 0.8140\n",
      "Epoch 86/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4027 - accuracy: 0.8157\n",
      "Epoch 87/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4012 - accuracy: 0.8149\n",
      "Epoch 88/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4009 - accuracy: 0.8145\n",
      "Epoch 89/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4006 - accuracy: 0.8161\n",
      "Epoch 90/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.4016 - accuracy: 0.8151\n",
      "Epoch 91/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3992 - accuracy: 0.8174\n",
      "Epoch 92/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3985 - accuracy: 0.8176\n",
      "Epoch 93/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3995 - accuracy: 0.8169\n",
      "Epoch 94/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3990 - accuracy: 0.8182\n",
      "Epoch 95/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3972 - accuracy: 0.8188\n",
      "Epoch 96/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3975 - accuracy: 0.8190\n",
      "Epoch 97/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3969 - accuracy: 0.8168\n",
      "Epoch 98/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3967 - accuracy: 0.8170\n",
      "Epoch 99/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3951 - accuracy: 0.8192\n",
      "Epoch 100/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3947 - accuracy: 0.8191\n",
      "Epoch 101/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3974 - accuracy: 0.8176\n",
      "Epoch 102/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3955 - accuracy: 0.8183\n",
      "Epoch 103/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3959 - accuracy: 0.8183\n",
      "Epoch 104/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3951 - accuracy: 0.8193\n",
      "Epoch 105/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3936 - accuracy: 0.8195\n",
      "Epoch 106/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3926 - accuracy: 0.8208\n",
      "Epoch 107/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3927 - accuracy: 0.8196\n",
      "Epoch 108/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3917 - accuracy: 0.8219\n",
      "Epoch 109/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3926 - accuracy: 0.8201\n",
      "Epoch 110/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3926 - accuracy: 0.8197\n",
      "Epoch 111/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3908 - accuracy: 0.8206\n",
      "Epoch 112/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3918 - accuracy: 0.8213\n",
      "Epoch 113/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3909 - accuracy: 0.8219\n",
      "Epoch 114/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3915 - accuracy: 0.8213\n",
      "Epoch 115/200\n",
      "1657/1657 [==============================] - 4s 3ms/step - loss: 0.3921 - accuracy: 0.8199\n",
      "Epoch 116/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3894 - accuracy: 0.8214\n",
      "Epoch 117/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3890 - accuracy: 0.8221\n",
      "Epoch 118/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3895 - accuracy: 0.8222\n",
      "Epoch 119/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3899 - accuracy: 0.8211\n",
      "Epoch 120/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3888 - accuracy: 0.8236\n",
      "Epoch 121/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3888 - accuracy: 0.8209\n",
      "Epoch 122/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3882 - accuracy: 0.8234\n",
      "Epoch 123/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3876 - accuracy: 0.8236\n",
      "Epoch 124/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3880 - accuracy: 0.8236\n",
      "Epoch 125/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3879 - accuracy: 0.8230\n",
      "Epoch 126/200\n",
      "1657/1657 [==============================] - 2s 2ms/step - loss: 0.3875 - accuracy: 0.8231\n",
      "Epoch 127/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3865 - accuracy: 0.8241\n",
      "Epoch 128/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3852 - accuracy: 0.8248\n",
      "Epoch 129/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3862 - accuracy: 0.8229\n",
      "Epoch 130/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3853 - accuracy: 0.8232\n",
      "Epoch 131/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3860 - accuracy: 0.8246\n",
      "Epoch 132/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3842 - accuracy: 0.8255\n",
      "Epoch 133/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3845 - accuracy: 0.8241\n",
      "Epoch 134/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3848 - accuracy: 0.8251\n",
      "Epoch 135/200\n",
      "1657/1657 [==============================] - 2s 2ms/step - loss: 0.3856 - accuracy: 0.8247\n",
      "Epoch 136/200\n",
      "1657/1657 [==============================] - 2s 2ms/step - loss: 0.3853 - accuracy: 0.8251\n",
      "Epoch 137/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3847 - accuracy: 0.8234\n",
      "Epoch 138/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3845 - accuracy: 0.8243\n",
      "Epoch 139/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3829 - accuracy: 0.8255\n",
      "Epoch 140/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3839 - accuracy: 0.8260\n",
      "Epoch 141/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3833 - accuracy: 0.8244\n",
      "Epoch 142/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3835 - accuracy: 0.8271\n",
      "Epoch 143/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3834 - accuracy: 0.8250\n",
      "Epoch 144/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3835 - accuracy: 0.8256\n",
      "Epoch 145/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3822 - accuracy: 0.8253\n",
      "Epoch 146/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3817 - accuracy: 0.8252\n",
      "Epoch 147/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3824 - accuracy: 0.8266\n",
      "Epoch 148/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3818 - accuracy: 0.8263\n",
      "Epoch 149/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3821 - accuracy: 0.8254\n",
      "Epoch 150/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3818 - accuracy: 0.8265\n",
      "Epoch 151/200\n",
      "1657/1657 [==============================] - 2s 2ms/step - loss: 0.3828 - accuracy: 0.8251\n",
      "Epoch 152/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3811 - accuracy: 0.8264\n",
      "Epoch 153/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3814 - accuracy: 0.8271\n",
      "Epoch 154/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3810 - accuracy: 0.8263\n",
      "Epoch 155/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3813 - accuracy: 0.8255\n",
      "Epoch 156/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3794 - accuracy: 0.8267\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3801 - accuracy: 0.8264\n",
      "Epoch 158/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3807 - accuracy: 0.8271\n",
      "Epoch 159/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3798 - accuracy: 0.8266\n",
      "Epoch 160/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3793 - accuracy: 0.8273\n",
      "Epoch 161/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3799 - accuracy: 0.8271\n",
      "Epoch 162/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3792 - accuracy: 0.8276\n",
      "Epoch 163/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3807 - accuracy: 0.8255\n",
      "Epoch 164/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3790 - accuracy: 0.8271\n",
      "Epoch 165/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3803 - accuracy: 0.8268\n",
      "Epoch 166/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3796 - accuracy: 0.8263\n",
      "Epoch 167/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3801 - accuracy: 0.8267\n",
      "Epoch 168/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3790 - accuracy: 0.8273\n",
      "Epoch 169/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3804 - accuracy: 0.8261\n",
      "Epoch 170/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3773 - accuracy: 0.8282\n",
      "Epoch 171/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3793 - accuracy: 0.8265\n",
      "Epoch 172/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3770 - accuracy: 0.8275\n",
      "Epoch 173/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3788 - accuracy: 0.8272\n",
      "Epoch 174/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3778 - accuracy: 0.8282\n",
      "Epoch 175/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3782 - accuracy: 0.8277\n",
      "Epoch 176/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3785 - accuracy: 0.8271\n",
      "Epoch 177/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3760 - accuracy: 0.8296\n",
      "Epoch 178/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3768 - accuracy: 0.8284\n",
      "Epoch 179/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3763 - accuracy: 0.8297\n",
      "Epoch 180/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3755 - accuracy: 0.8286\n",
      "Epoch 181/200\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.3755 - accuracy: 0.8299\n",
      "Epoch 182/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3757 - accuracy: 0.8297\n",
      "Epoch 183/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3767 - accuracy: 0.8279\n",
      "Epoch 184/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3755 - accuracy: 0.8292\n",
      "Epoch 185/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3753 - accuracy: 0.8282\n",
      "Epoch 186/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3747 - accuracy: 0.8287\n",
      "Epoch 187/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3757 - accuracy: 0.8282\n",
      "Epoch 188/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3746 - accuracy: 0.8287\n",
      "Epoch 189/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3745 - accuracy: 0.8282\n",
      "Epoch 190/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3744 - accuracy: 0.8293\n",
      "Epoch 191/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3750 - accuracy: 0.8281\n",
      "Epoch 192/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3733 - accuracy: 0.8302\n",
      "Epoch 193/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3735 - accuracy: 0.8293\n",
      "Epoch 194/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3754 - accuracy: 0.8294\n",
      "Epoch 195/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3724 - accuracy: 0.8292\n",
      "Epoch 196/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3732 - accuracy: 0.8297\n",
      "Epoch 197/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3727 - accuracy: 0.8298\n",
      "Epoch 198/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3722 - accuracy: 0.8312\n",
      "Epoch 199/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3722 - accuracy: 0.8309\n",
      "Epoch 200/200\n",
      "1657/1657 [==============================] - 3s 2ms/step - loss: 0.3731 - accuracy: 0.8299\n"
     ]
    }
   ],
   "source": [
    "model_4 = nn4.fit(X_train_scaled, y_train, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b3ae6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553/553 - 1s - loss: 0.6646 - accuracy: 0.7062 - 589ms/epoch - 1ms/step\n",
      "loss: 0.6645819544792175, accuracy: 0.7062185406684875\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model using the test data\n",
    "model_loss, model_accuracy = nn4.evaluate(X_test_scaled, y_test, verbose = 2)\n",
    "print(f'loss: {model_loss}, accuracy: {model_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9996bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest (200 estimators) - feature importance and feature correlation map (heat map)\n",
    "# Importing dependencies\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "55e3bce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a random forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators = 200, random_state = 66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "30cbd007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f7b911e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200, random_state=66)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200, random_state=66)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, random_state=66)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf753bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb6daa8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>6082</td>\n",
       "      <td>2648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>1978</td>\n",
       "      <td>6965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         6082         2648\n",
       "Actual 1         1978         6965"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index = ['Actual 0', 'Actual 1'], columns = ['Predicted 0', 'Predicted 1']\n",
    ")\n",
    "\n",
    "display(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2314df0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7382447801731454\n"
     ]
    }
   ],
   "source": [
    "# Calculating Accuracy Score\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy Score: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13fb4426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.70      0.72      8730\n",
      "         1.0       0.72      0.78      0.75      8943\n",
      "\n",
      "    accuracy                           0.74     17673\n",
      "   macro avg       0.74      0.74      0.74     17673\n",
      "weighted avg       0.74      0.74      0.74     17673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(f'Classification Report: {classification_report(y_test, predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5842a007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70687</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70688</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70689</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70690</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70691</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70692 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0         1.0       0.0        1.0  26.0     0.0     0.0   \n",
       "1         1.0       1.0        1.0  26.0     1.0     1.0   \n",
       "2         0.0       0.0        1.0  26.0     0.0     0.0   \n",
       "3         1.0       1.0        1.0  28.0     1.0     0.0   \n",
       "4         0.0       0.0        1.0  29.0     1.0     0.0   \n",
       "...       ...       ...        ...   ...     ...     ...   \n",
       "70687     0.0       1.0        1.0  37.0     0.0     0.0   \n",
       "70688     0.0       1.0        1.0  29.0     1.0     0.0   \n",
       "70689     1.0       1.0        1.0  25.0     0.0     0.0   \n",
       "70690     1.0       1.0        1.0  18.0     0.0     0.0   \n",
       "70691     1.0       1.0        1.0  25.0     0.0     0.0   \n",
       "\n",
       "       HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  ...  \\\n",
       "0                       0.0           1.0     0.0      1.0  ...   \n",
       "1                       0.0           0.0     1.0      0.0  ...   \n",
       "2                       0.0           1.0     1.0      1.0  ...   \n",
       "3                       0.0           1.0     1.0      1.0  ...   \n",
       "4                       0.0           1.0     1.0      1.0  ...   \n",
       "...                     ...           ...     ...      ...  ...   \n",
       "70687                   0.0           0.0     0.0      1.0  ...   \n",
       "70688                   1.0           0.0     1.0      1.0  ...   \n",
       "70689                   1.0           0.0     1.0      0.0  ...   \n",
       "70690                   0.0           0.0     0.0      0.0  ...   \n",
       "70691                   1.0           1.0     1.0      0.0  ...   \n",
       "\n",
       "       AnyHealthcare  NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex  \\\n",
       "0                1.0          0.0      3.0       5.0      30.0       0.0  1.0   \n",
       "1                1.0          0.0      3.0       0.0       0.0       0.0  1.0   \n",
       "2                1.0          0.0      1.0       0.0      10.0       0.0  1.0   \n",
       "3                1.0          0.0      3.0       0.0       3.0       0.0  1.0   \n",
       "4                1.0          0.0      2.0       0.0       0.0       0.0  0.0   \n",
       "...              ...          ...      ...       ...       ...       ...  ...   \n",
       "70687            1.0          0.0      4.0       0.0       0.0       0.0  0.0   \n",
       "70688            1.0          0.0      2.0       0.0       0.0       1.0  1.0   \n",
       "70689            1.0          0.0      5.0      15.0       0.0       1.0  0.0   \n",
       "70690            1.0          0.0      4.0       0.0       0.0       1.0  0.0   \n",
       "70691            1.0          0.0      2.0       0.0       0.0       0.0  0.0   \n",
       "\n",
       "        Age  Education  Income  \n",
       "0       4.0        6.0     8.0  \n",
       "1      12.0        6.0     8.0  \n",
       "2      13.0        6.0     8.0  \n",
       "3      11.0        6.0     8.0  \n",
       "4       8.0        5.0     8.0  \n",
       "...     ...        ...     ...  \n",
       "70687   6.0        4.0     1.0  \n",
       "70688  10.0        3.0     6.0  \n",
       "70689  13.0        6.0     4.0  \n",
       "70690  11.0        2.0     4.0  \n",
       "70691   9.0        6.0     2.0  \n",
       "\n",
       "[70692 rows x 21 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df = x = df.drop('Diabetes_binary', axis = 1)\n",
    "x_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "664b207e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.170671</td>\n",
       "      <td>BMI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.126248</td>\n",
       "      <td>Age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.105744</td>\n",
       "      <td>GenHlth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083055</td>\n",
       "      <td>Income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.074402</td>\n",
       "      <td>HighBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.068595</td>\n",
       "      <td>PhysHlth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.057202</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.051707</td>\n",
       "      <td>MentHlth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.042078</td>\n",
       "      <td>HighChol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.028399</td>\n",
       "      <td>Smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.028268</td>\n",
       "      <td>Fruits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.027529</td>\n",
       "      <td>DiffWalk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.026744</td>\n",
       "      <td>Sex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.023392</td>\n",
       "      <td>PhysActivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.021647</td>\n",
       "      <td>Veggies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.018972</td>\n",
       "      <td>HeartDiseaseorAttack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.012186</td>\n",
       "      <td>NoDocbcCost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.009949</td>\n",
       "      <td>Stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.009672</td>\n",
       "      <td>HvyAlcoholConsump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.007306</td>\n",
       "      <td>AnyHealthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.006236</td>\n",
       "      <td>CholCheck</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                     1\n",
       "0   0.170671                   BMI\n",
       "1   0.126248                   Age\n",
       "2   0.105744               GenHlth\n",
       "3   0.083055                Income\n",
       "4   0.074402                HighBP\n",
       "5   0.068595              PhysHlth\n",
       "6   0.057202             Education\n",
       "7   0.051707              MentHlth\n",
       "8   0.042078              HighChol\n",
       "9   0.028399                Smoker\n",
       "10  0.028268                Fruits\n",
       "11  0.027529              DiffWalk\n",
       "12  0.026744                   Sex\n",
       "13  0.023392          PhysActivity\n",
       "14  0.021647               Veggies\n",
       "15  0.018972  HeartDiseaseorAttack\n",
       "16  0.012186           NoDocbcCost\n",
       "17  0.009949                Stroke\n",
       "18  0.009672     HvyAlcoholConsump\n",
       "19  0.007306         AnyHealthcare\n",
       "20  0.006236             CholCheck"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating Feature Importance\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "importances_df = pd.DataFrame(sorted(zip(rf_model.feature_importances_, x_df.columns), reverse = True))\n",
    "importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8c66e423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.170671</td>\n",
       "      <td>BMI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.126248</td>\n",
       "      <td>Age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenHlth</th>\n",
       "      <td>0.105744</td>\n",
       "      <td>GenHlth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income</th>\n",
       "      <td>0.083055</td>\n",
       "      <td>Income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighBP</th>\n",
       "      <td>0.074402</td>\n",
       "      <td>HighBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysHlth</th>\n",
       "      <td>0.068595</td>\n",
       "      <td>PhysHlth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.057202</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MentHlth</th>\n",
       "      <td>0.051707</td>\n",
       "      <td>MentHlth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighChol</th>\n",
       "      <td>0.042078</td>\n",
       "      <td>HighChol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoker</th>\n",
       "      <td>0.028399</td>\n",
       "      <td>Smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fruits</th>\n",
       "      <td>0.028268</td>\n",
       "      <td>Fruits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiffWalk</th>\n",
       "      <td>0.027529</td>\n",
       "      <td>DiffWalk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.026744</td>\n",
       "      <td>Sex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysActivity</th>\n",
       "      <td>0.023392</td>\n",
       "      <td>PhysActivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veggies</th>\n",
       "      <td>0.021647</td>\n",
       "      <td>Veggies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <td>0.018972</td>\n",
       "      <td>HeartDiseaseorAttack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <td>0.012186</td>\n",
       "      <td>NoDocbcCost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stroke</th>\n",
       "      <td>0.009949</td>\n",
       "      <td>Stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <td>0.009672</td>\n",
       "      <td>HvyAlcoholConsump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <td>0.007306</td>\n",
       "      <td>AnyHealthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CholCheck</th>\n",
       "      <td>0.006236</td>\n",
       "      <td>CholCheck</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0                     1\n",
       "1                                                   \n",
       "BMI                   0.170671                   BMI\n",
       "Age                   0.126248                   Age\n",
       "GenHlth               0.105744               GenHlth\n",
       "Income                0.083055                Income\n",
       "HighBP                0.074402                HighBP\n",
       "PhysHlth              0.068595              PhysHlth\n",
       "Education             0.057202             Education\n",
       "MentHlth              0.051707              MentHlth\n",
       "HighChol              0.042078              HighChol\n",
       "Smoker                0.028399                Smoker\n",
       "Fruits                0.028268                Fruits\n",
       "DiffWalk              0.027529              DiffWalk\n",
       "Sex                   0.026744                   Sex\n",
       "PhysActivity          0.023392          PhysActivity\n",
       "Veggies               0.021647               Veggies\n",
       "HeartDiseaseorAttack  0.018972  HeartDiseaseorAttack\n",
       "NoDocbcCost           0.012186           NoDocbcCost\n",
       "Stroke                0.009949                Stroke\n",
       "HvyAlcoholConsump     0.009672     HvyAlcoholConsump\n",
       "AnyHealthcare         0.007306         AnyHealthcare\n",
       "CholCheck             0.006236             CholCheck"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances_df.set_index(importances_df[1], inplace=True)\n",
    "importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "04a2f865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.170671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.126248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenHlth</th>\n",
       "      <td>0.105744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income</th>\n",
       "      <td>0.083055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighBP</th>\n",
       "      <td>0.074402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysHlth</th>\n",
       "      <td>0.068595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.057202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MentHlth</th>\n",
       "      <td>0.051707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighChol</th>\n",
       "      <td>0.042078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoker</th>\n",
       "      <td>0.028399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fruits</th>\n",
       "      <td>0.028268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiffWalk</th>\n",
       "      <td>0.027529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.026744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysActivity</th>\n",
       "      <td>0.023392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veggies</th>\n",
       "      <td>0.021647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <td>0.018972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <td>0.012186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stroke</th>\n",
       "      <td>0.009949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <td>0.009672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <td>0.007306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CholCheck</th>\n",
       "      <td>0.006236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0\n",
       "1                             \n",
       "BMI                   0.170671\n",
       "Age                   0.126248\n",
       "GenHlth               0.105744\n",
       "Income                0.083055\n",
       "HighBP                0.074402\n",
       "PhysHlth              0.068595\n",
       "Education             0.057202\n",
       "MentHlth              0.051707\n",
       "HighChol              0.042078\n",
       "Smoker                0.028399\n",
       "Fruits                0.028268\n",
       "DiffWalk              0.027529\n",
       "Sex                   0.026744\n",
       "PhysActivity          0.023392\n",
       "Veggies               0.021647\n",
       "HeartDiseaseorAttack  0.018972\n",
       "NoDocbcCost           0.012186\n",
       "Stroke                0.009949\n",
       "HvyAlcoholConsump     0.009672\n",
       "AnyHealthcare         0.007306\n",
       "CholCheck             0.006236"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances_df.drop(columns=1, inplace=True)\n",
    "importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d6a73372",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_df.rename(columns={0: 'Feature Importances'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "47d69734",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_sorted = importances_df.sort_values(by='Feature Importances', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8a546f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Importances</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CholCheck</th>\n",
       "      <td>0.006236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <td>0.007306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <td>0.009672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stroke</th>\n",
       "      <td>0.009949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <td>0.012186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <td>0.018972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veggies</th>\n",
       "      <td>0.021647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysActivity</th>\n",
       "      <td>0.023392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.026744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiffWalk</th>\n",
       "      <td>0.027529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fruits</th>\n",
       "      <td>0.028268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoker</th>\n",
       "      <td>0.028399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighChol</th>\n",
       "      <td>0.042078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MentHlth</th>\n",
       "      <td>0.051707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.057202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysHlth</th>\n",
       "      <td>0.068595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighBP</th>\n",
       "      <td>0.074402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income</th>\n",
       "      <td>0.083055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenHlth</th>\n",
       "      <td>0.105744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.126248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.170671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Feature Importances\n",
       "1                                        \n",
       "CholCheck                        0.006236\n",
       "AnyHealthcare                    0.007306\n",
       "HvyAlcoholConsump                0.009672\n",
       "Stroke                           0.009949\n",
       "NoDocbcCost                      0.012186\n",
       "HeartDiseaseorAttack             0.018972\n",
       "Veggies                          0.021647\n",
       "PhysActivity                     0.023392\n",
       "Sex                              0.026744\n",
       "DiffWalk                         0.027529\n",
       "Fruits                           0.028268\n",
       "Smoker                           0.028399\n",
       "HighChol                         0.042078\n",
       "MentHlth                         0.051707\n",
       "Education                        0.057202\n",
       "PhysHlth                         0.068595\n",
       "HighBP                           0.074402\n",
       "Income                           0.083055\n",
       "GenHlth                          0.105744\n",
       "Age                              0.126248\n",
       "BMI                              0.170671"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "99620188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Feature Importances'}, ylabel='1'>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances_sorted.plot(kind = 'barh', title = 'Feature Importances', legend = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bbf34d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Diabetes_binary', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker',\n",
       "       'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
       "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
       "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
       "       'Income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second RandomForest model with more relevant columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "73965a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up x and y variables\n",
    "x2 = df[['BMI', 'Age', 'GenHlth', 'Income', 'HighBP', 'PhysHlth', 'Education', 'MentHlth', 'HighChol']]\n",
    "y2 = df['Diabetes_binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4558b0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>Age</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>Income</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>Education</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>HighChol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70687</th>\n",
       "      <td>37.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70688</th>\n",
       "      <td>29.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70689</th>\n",
       "      <td>25.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70690</th>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70691</th>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70692 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BMI   Age  GenHlth  Income  HighBP  PhysHlth  Education  MentHlth  \\\n",
       "0      26.0   4.0      3.0     8.0     1.0      30.0        6.0       5.0   \n",
       "1      26.0  12.0      3.0     8.0     1.0       0.0        6.0       0.0   \n",
       "2      26.0  13.0      1.0     8.0     0.0      10.0        6.0       0.0   \n",
       "3      28.0  11.0      3.0     8.0     1.0       3.0        6.0       0.0   \n",
       "4      29.0   8.0      2.0     8.0     0.0       0.0        5.0       0.0   \n",
       "...     ...   ...      ...     ...     ...       ...        ...       ...   \n",
       "70687  37.0   6.0      4.0     1.0     0.0       0.0        4.0       0.0   \n",
       "70688  29.0  10.0      2.0     6.0     0.0       0.0        3.0       0.0   \n",
       "70689  25.0  13.0      5.0     4.0     1.0       0.0        6.0      15.0   \n",
       "70690  18.0  11.0      4.0     4.0     1.0       0.0        2.0       0.0   \n",
       "70691  25.0   9.0      2.0     2.0     1.0       0.0        6.0       0.0   \n",
       "\n",
       "       HighChol  \n",
       "0           0.0  \n",
       "1           1.0  \n",
       "2           0.0  \n",
       "3           1.0  \n",
       "4           0.0  \n",
       "...         ...  \n",
       "70687       1.0  \n",
       "70688       1.0  \n",
       "70689       1.0  \n",
       "70690       1.0  \n",
       "70691       1.0  \n",
       "\n",
       "[70692 rows x 9 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "552ce96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "        ... \n",
       "70687    1.0\n",
       "70688    1.0\n",
       "70689    1.0\n",
       "70690    1.0\n",
       "70691    1.0\n",
       "Name: Diabetes_binary, Length: 70692, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5ee80ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test sets\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(x2, y2, random_state = 66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e0a305aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dbaa277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_scaler = scaler.fit(X2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "14ccef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train_scaled = X2_scaler.transform(X2_train)\n",
    "X2_test_scaled = X2_scaler.transform(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e1072271",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_2 = RandomForestClassifier(n_estimators = 200, random_state = 66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7847a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_2 = rf_model_2.fit(X2_train_scaled, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ff71add6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = rf_model_2.predict(X2_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "edc60718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>5955</td>\n",
       "      <td>2775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>2280</td>\n",
       "      <td>6663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         5955         2775\n",
       "Actual 1         2280         6663"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm2 = confusion_matrix(y2_test, predictions2)\n",
    "cm2_df = pd.DataFrame(\n",
    "    cm2, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "display(cm2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ee07c670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7139704634187743\n"
     ]
    }
   ],
   "source": [
    "accuracy2 = accuracy_score(y2_test, predictions2)\n",
    "print(f'Accuracy Score: {accuracy2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "731a1ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.68      0.70      8730\n",
      "         1.0       0.71      0.75      0.72      8943\n",
      "\n",
      "    accuracy                           0.71     17673\n",
      "   macro avg       0.71      0.71      0.71     17673\n",
      "weighted avg       0.71      0.71      0.71     17673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Classification Report: {classification_report(y2_test, predictions2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "df4237b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.22049168191700752, 'BMI'),\n",
       " (0.15352731418964932, 'Age'),\n",
       " (0.1321299445220992, 'GenHlth'),\n",
       " (0.11254869134750183, 'Income'),\n",
       " (0.09594484295553247, 'PhysHlth'),\n",
       " (0.09392905949438383, 'HighBP'),\n",
       " (0.0758913650585897, 'Education'),\n",
       " (0.0751250480572076, 'MentHlth'),\n",
       " (0.040412052458028536, 'HighChol')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances2 = rf_model_2.feature_importances_\n",
    "importances2_df = sorted(zip(rf_model_2.feature_importances_, x2.columns), reverse=True)\n",
    "importances2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bffccb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0              0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1              0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2              0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3              0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4              0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           0.0     0.0  ...            1.0   \n",
       "1                   0.0           1.0     0.0  ...            0.0   \n",
       "2                   0.0           0.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
       "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
       "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
       "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
       "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
       "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
       "\n",
       "   Income  \n",
       "0     3.0  \n",
       "1     1.0  \n",
       "2     8.0  \n",
       "3     6.0  \n",
       "4     4.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Analysis for BMI and Age variables\n",
    "\n",
    "# Getting dataset\n",
    "data_analysis = pd.read_csv('diabetes_binary_health_indicators_BRFSS2015.csv')\n",
    "data_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09197da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253680 entries, 0 to 253679\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   Diabetes_binary       253680 non-null  float64\n",
      " 1   HighBP                253680 non-null  float64\n",
      " 2   HighChol              253680 non-null  float64\n",
      " 3   CholCheck             253680 non-null  float64\n",
      " 4   BMI                   253680 non-null  float64\n",
      " 5   Smoker                253680 non-null  float64\n",
      " 6   Stroke                253680 non-null  float64\n",
      " 7   HeartDiseaseorAttack  253680 non-null  float64\n",
      " 8   PhysActivity          253680 non-null  float64\n",
      " 9   Fruits                253680 non-null  float64\n",
      " 10  Veggies               253680 non-null  float64\n",
      " 11  HvyAlcoholConsump     253680 non-null  float64\n",
      " 12  AnyHealthcare         253680 non-null  float64\n",
      " 13  NoDocbcCost           253680 non-null  float64\n",
      " 14  GenHlth               253680 non-null  float64\n",
      " 15  MentHlth              253680 non-null  float64\n",
      " 16  PhysHlth              253680 non-null  float64\n",
      " 17  DiffWalk              253680 non-null  float64\n",
      " 18  Sex                   253680 non-null  float64\n",
      " 19  Age                   253680 non-null  float64\n",
      " 20  Education             253680 non-null  float64\n",
      " 21  Income                253680 non-null  float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 42.6 MB\n"
     ]
    }
   ],
   "source": [
    "data_analysis.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eae67332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253675</th>\n",
       "      <td>45.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253676</th>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253677</th>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253678</th>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253679</th>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253680 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         BMI   Age\n",
       "0       40.0   9.0\n",
       "1       25.0   7.0\n",
       "2       28.0   9.0\n",
       "3       27.0  11.0\n",
       "4       24.0  11.0\n",
       "...      ...   ...\n",
       "253675  45.0   5.0\n",
       "253676  18.0  11.0\n",
       "253677  28.0   2.0\n",
       "253678  23.0   7.0\n",
       "253679  25.0   9.0\n",
       "\n",
       "[253680 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_analysis[['BMI', 'Age']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56609461",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmi = data['BMI']\n",
    "age = data['Age']\n",
    "bmi = pd.DataFrame(bmi)\n",
    "age = pd.DataFrame(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fd57708",
   "metadata": {},
   "outputs": [],
   "source": [
    "age['Age'] = age['Age'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a774ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "age['Age'] = age['Age'].replace('1.0', '18-24')\n",
    "age['Age'] = age['Age'].replace('2.0', '25-29')\n",
    "age['Age'] = age['Age'].replace('3.0', '30-34')\n",
    "age['Age'] = age['Age'].replace('4.0', '35-39')\n",
    "age['Age'] = age['Age'].replace('5.0', '40-44')\n",
    "age['Age'] = age['Age'].replace('6.0', '45-49')\n",
    "age['Age'] = age['Age'].replace('7.0', '50-54')\n",
    "age['Age'] = age['Age'].replace('8.0', '55-59')\n",
    "age['Age'] = age['Age'].replace('9.0', '60-64')\n",
    "age['Age'] = age['Age'].replace('10.0', '65-69')\n",
    "age['Age'] = age['Age'].replace('11.0', '70-74')\n",
    "age['Age'] = age['Age'].replace('12.0', '75-79')\n",
    "age['Age'] = age['Age'].replace('13.0', '80+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb6a8c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age  \n",
       "60-64    33244\n",
       "65-69    32194\n",
       "55-59    30832\n",
       "50-54    26314\n",
       "70-74    23533\n",
       "45-49    19819\n",
       "80+      17363\n",
       "40-44    16157\n",
       "75-79    15980\n",
       "35-39    13823\n",
       "30-34    11123\n",
       "25-29     7598\n",
       "18-24     5700\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a31e0ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "age['Age'] = age['Age'].replace('18 - 24', '18-24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f00385ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BMI \n",
       "27.0    24606\n",
       "26.0    20562\n",
       "24.0    19550\n",
       "25.0    17146\n",
       "28.0    16545\n",
       "        ...  \n",
       "86.0        1\n",
       "90.0        1\n",
       "91.0        1\n",
       "78.0        1\n",
       "96.0        1\n",
       "Length: 84, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmi.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97a6910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39d7d711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253680, 22)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_analysis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a0abe9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253676</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253677</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253678</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253679</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253680 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0                   0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1                   0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2                   0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3                   0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4                   0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "...                 ...     ...       ...        ...   ...     ...     ...   \n",
       "253675              0.0     1.0       1.0        1.0  45.0     0.0     0.0   \n",
       "253676              1.0     1.0       1.0        1.0  18.0     0.0     0.0   \n",
       "253677              0.0     0.0       0.0        1.0  28.0     0.0     0.0   \n",
       "253678              0.0     1.0       0.0        1.0  23.0     0.0     0.0   \n",
       "253679              1.0     1.0       1.0        1.0  25.0     0.0     0.0   \n",
       "\n",
       "        HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                        0.0           0.0     0.0  ...            1.0   \n",
       "1                        0.0           1.0     0.0  ...            0.0   \n",
       "2                        0.0           0.0     1.0  ...            1.0   \n",
       "3                        0.0           1.0     1.0  ...            1.0   \n",
       "4                        0.0           1.0     1.0  ...            1.0   \n",
       "...                      ...           ...     ...  ...            ...   \n",
       "253675                   0.0           0.0     1.0  ...            1.0   \n",
       "253676                   0.0           0.0     0.0  ...            1.0   \n",
       "253677                   0.0           1.0     1.0  ...            1.0   \n",
       "253678                   0.0           0.0     1.0  ...            1.0   \n",
       "253679                   1.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "        NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  \\\n",
       "0               0.0      5.0      18.0      15.0       1.0  0.0   9.0   \n",
       "1               1.0      3.0       0.0       0.0       0.0  0.0   7.0   \n",
       "2               1.0      5.0      30.0      30.0       1.0  0.0   9.0   \n",
       "3               0.0      2.0       0.0       0.0       0.0  0.0  11.0   \n",
       "4               0.0      2.0       3.0       0.0       0.0  0.0  11.0   \n",
       "...             ...      ...       ...       ...       ...  ...   ...   \n",
       "253675          0.0      3.0       0.0       5.0       0.0  1.0   5.0   \n",
       "253676          0.0      4.0       0.0       0.0       1.0  0.0  11.0   \n",
       "253677          0.0      1.0       0.0       0.0       0.0  0.0   2.0   \n",
       "253678          0.0      3.0       0.0       0.0       0.0  1.0   7.0   \n",
       "253679          0.0      2.0       0.0       0.0       0.0  0.0   9.0   \n",
       "\n",
       "        Education  Income  \n",
       "0             4.0     3.0  \n",
       "1             6.0     1.0  \n",
       "2             4.0     8.0  \n",
       "3             3.0     6.0  \n",
       "4             5.0     4.0  \n",
       "...           ...     ...  \n",
       "253675        6.0     7.0  \n",
       "253676        2.0     4.0  \n",
       "253677        5.0     2.0  \n",
       "253678        5.0     1.0  \n",
       "253679        6.0     2.0  \n",
       "\n",
       "[253680 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba50b601",
   "metadata": {},
   "outputs": [],
   "source": [
    "rstudio_df = data_analysis[['Diabetes_binary', 'BMI', 'Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d78c0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253676</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253677</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253678</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253679</th>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253680 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Diabetes_binary   BMI   Age\n",
       "0                   0.0  40.0   9.0\n",
       "1                   0.0  25.0   7.0\n",
       "2                   0.0  28.0   9.0\n",
       "3                   0.0  27.0  11.0\n",
       "4                   0.0  24.0  11.0\n",
       "...                 ...   ...   ...\n",
       "253675              0.0  45.0   5.0\n",
       "253676              1.0  18.0  11.0\n",
       "253677              0.0  28.0   2.0\n",
       "253678              0.0  23.0   7.0\n",
       "253679              1.0  25.0   9.0\n",
       "\n",
       "[253680 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rstudio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "855d7c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "rstudio_df.to_csv('rstudio.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd268374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
